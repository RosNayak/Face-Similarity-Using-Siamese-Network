{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\n!pip install transformers\n!pip install timm\n!pip install -qq albumentations==1.0.3","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:13.364504Z","iopub.execute_input":"2022-04-28T17:12:13.365020Z","iopub.status.idle":"2022-04-28T17:12:49.581075Z","shell.execute_reply.started":"2022-04-28T17:12:13.364981Z","shell.execute_reply":"2022-04-28T17:12:49.580120Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport timm\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.583173Z","iopub.execute_input":"2022-04-28T17:12:49.583414Z","iopub.status.idle":"2022-04-28T17:12:49.591433Z","shell.execute_reply.started":"2022-04-28T17:12:49.583384Z","shell.execute_reply":"2022-04-28T17:12:49.590740Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name = 'tf_efficientnet_b0' #efficient net.\n    train_path = '../input/face-images/faces/training'\n    test_path = '../input/face-images/faces/testing'\n    save_dir = './'\n    val_size = 0.2\n    seed = 42\n    batch_size = 16\n    lr = 1e-4\n    monitor = 'val_loss'\n    patience = 3\n    epochs = 4\n    accumulate = 1\n    loss_margin = 2.0\n    embed_dims = 64\n    \n    similarity_factor = 3\n    dissimilarity_factor = 3\n    test_similarity_factor = 2\n    test_dissimilarity_factor = 2","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.592930Z","iopub.execute_input":"2022-04-28T17:12:49.593485Z","iopub.status.idle":"2022-04-28T17:12:49.602386Z","shell.execute_reply.started":"2022-04-28T17:12:49.593447Z","shell.execute_reply":"2022-04-28T17:12:49.601608Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class SiameseDataset(Dataset):\n\n  def __init__(self, image_df, transform=None): #image_df contains image_id1, image_id2, label\n    self.image_df = image_df\n    self.transform = transform\n\n  def __len__(self):\n    return self.image_df.shape[0]\n\n  def __getitem__(self, index):\n    image1 = cv2.imread(self.image_df.image1.iloc[index])\n    image2 = cv2.imread(self.image_df.image2.iloc[index])\n    if self.transform is not None:\n        image1 = self.transform(image=image1)['image']\n        image2 = self.transform(image=image2)['image']\n    label = self.image_df.label.iloc[index]\n    return (image1, image2, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.604277Z","iopub.execute_input":"2022-04-28T17:12:49.604820Z","iopub.status.idle":"2022-04-28T17:12:49.613213Z","shell.execute_reply.started":"2022-04-28T17:12:49.604781Z","shell.execute_reply":"2022-04-28T17:12:49.612542Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n\n  def __init__(self, model_name):\n    super(SiameseNetwork, self).__init__()\n    self.embed_model = timm.create_model(model_name, pretrained=True)\n    feats = self.embed_model.classifier.in_features\n    self.embed_model.classifier = nn.Linear(feats, CFG.embed_dims)\n\n  def forward(self, image1, image2):\n    img1_embeds = self.embed_model(image1)\n    img2_embeds = self.embed_model(image2)\n    return img1_embeds, img2_embeds\n\nclass SiameseNetworkDirver(pl.LightningModule):\n\n    def __init__(self, model, criterion, lr):\n        super(SiameseNetworkDirver, self).__init__()\n        self.model = model\n        self.criterion = criterion\n\n    def forward(self, images1, images2):\n        return self.model(image1, image2)\n\n    def configure_optimizers(self):\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=CFG.lr)\n        return self.optimizer\n\n    def training_step(self, batch, batch_idx):\n        image1, image2, labels = batch[0], batch[1], batch[2]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        loss = self.criterion(img1_embeds, img2_embeds, labels)\n        logs = { 'train_loss': loss, 'lr': self.optimizer.param_groups[0]['lr'] }\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        image1, image2, labels = batch[0], batch[1], batch[2]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        loss = self.criterion(img1_embeds, img2_embeds, labels)\n        logs = { 'val_loss': loss }\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def predict_step(self, batch, batch_idx):\n        image1, image2 = batch[0], batch[1]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        return img1_embeds, img2_embeds","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.614505Z","iopub.execute_input":"2022-04-28T17:12:49.615244Z","iopub.status.idle":"2022-04-28T17:12:49.630351Z","shell.execute_reply.started":"2022-04-28T17:12:49.615208Z","shell.execute_reply":"2022-04-28T17:12:49.629611Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def train_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )\n\ndef valid_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.631697Z","iopub.execute_input":"2022-04-28T17:12:49.632166Z","iopub.status.idle":"2022-04-28T17:12:49.643659Z","shell.execute_reply.started":"2022-04-28T17:12:49.632129Z","shell.execute_reply":"2022-04-28T17:12:49.642898Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class SimilarityLoss(nn.Module):\n\n  def __init__(self, margin=2.0):\n    super(SimilarityLoss, self).__init__()\n    self.margin = margin\n\n  def forward(self, img1_embeds, img2_embeds, label):\n    euclidean_distance = F.pairwise_distance(img1_embeds, img2_embeds, keepdim=True)\n    loss = torch.mean((label*torch.pow(euclidean_distance, 2) + \n                      (1 - label)*torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.644888Z","iopub.execute_input":"2022-04-28T17:12:49.645697Z","iopub.status.idle":"2022-04-28T17:12:49.656077Z","shell.execute_reply.started":"2022-04-28T17:12:49.645660Z","shell.execute_reply":"2022-04-28T17:12:49.655345Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def append_to_data(path, image, imgs, label, data):\n    image_path = os.path.join(path, image)\n    for img in imgs:\n        img_path = os.path.join(path, img)\n#         if [img_path, image_path, label] not in data:\n#             data.append([image_path, img_path, label])\n        data.append([image_path, img_path, label])\n    return data\n\ndef create_dataset(path, s_factor, ds_factor):\n    data = []   \n\n    folders = os.listdir(path)\n    if 'README' in folders:\n        folders.remove('README')\n\n    file_names = {}\n    for folder in folders:\n        files = os.listdir(os.path.join(path, folder))\n        images = [os.path.join(folder, file) for file in files if file.endswith('.png')]\n        file_names[folder] = images\n\n    for folder in tqdm(folders):\n        images = file_names[folder]\n        temp = folders.copy()\n        temp.remove(folder)\n        for image in images:\n            imgs = random.sample(images, s_factor + 1)\n            if image in imgs:\n                imgs.remove(image)\n            else:\n                imgs = imgs[:-1]\n            data = append_to_data(path, image, imgs, 1, data)\n\n            sel_fs = random.sample(temp, ds_factor)\n            imgs = []\n            for f in sel_fs:\n                imgs.append(random.sample(file_names[f], 1)[0])\n            data = append_to_data(path, image, imgs, 0, data)\n    \n    return data\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.657443Z","iopub.execute_input":"2022-04-28T17:12:49.658279Z","iopub.status.idle":"2022-04-28T17:12:49.670288Z","shell.execute_reply.started":"2022-04-28T17:12:49.658242Z","shell.execute_reply":"2022-04-28T17:12:49.669547Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"data = create_dataset(CFG.train_path, CFG.similarity_factor, CFG.dissimilarity_factor)\ndataframe = pd.DataFrame(data, columns=['image1', 'image2', 'label'])\nprint(dataframe.shape)\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.671551Z","iopub.execute_input":"2022-04-28T17:12:49.672151Z","iopub.status.idle":"2022-04-28T17:12:49.742119Z","shell.execute_reply.started":"2022-04-28T17:12:49.672114Z","shell.execute_reply":"2022-04-28T17:12:49.741467Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"dataframe.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.744455Z","iopub.execute_input":"2022-04-28T17:12:49.745026Z","iopub.status.idle":"2022-04-28T17:12:49.752543Z","shell.execute_reply.started":"2022-04-28T17:12:49.744989Z","shell.execute_reply":"2022-04-28T17:12:49.751796Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"labels = dataframe.label.values\ndataframe.drop('label', inplace=True, axis=1)\ntrain_data, val_data, train_labels, val_labels = train_test_split(dataframe, labels, \n                                                                  stratify=labels, \n                                                                  test_size=CFG.val_size, \n                                                                  random_state=CFG.seed)\ntrain_data['label'] = train_labels\nval_data['label'] = val_labels\n\ntransform = train_transform_object(256)\ntrain_dataset = SiameseDataset(train_data, transform)\nval_dataset = SiameseDataset(val_data, transform)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.754023Z","iopub.execute_input":"2022-04-28T17:12:49.754541Z","iopub.status.idle":"2022-04-28T17:12:49.767300Z","shell.execute_reply.started":"2022-04-28T17:12:49.754506Z","shell.execute_reply":"2022-04-28T17:12:49.766611Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"logger = CSVLogger(save_dir=CFG.save_dir, name=CFG.model_name+'_logs')\nlogger.log_hyperparams(CFG.__dict__)\n\ncheckpoint_callback = ModelCheckpoint(monitor=CFG.monitor,\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='{epoch:02d}-{valid_loss:.4f}-{valid_acc:.4f}',\n                                      verbose=False,\n                                      mode='min')\n\nearly_stop_callback = EarlyStopping(monitor=CFG.monitor, \n                                    patience=CFG.patience, \n                                    verbose=False, \n                                    mode=\"min\")\n\ntrainer = Trainer(\n    max_epochs=CFG.epochs,\n    gpus=[0],\n    accumulate_grad_batches=CFG.accumulate,\n    callbacks=[checkpoint_callback, early_stop_callback], \n    logger=logger,\n    weights_summary='top',\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.769059Z","iopub.execute_input":"2022-04-28T17:12:49.769869Z","iopub.status.idle":"2022-04-28T17:12:49.782324Z","shell.execute_reply.started":"2022-04-28T17:12:49.769832Z","shell.execute_reply":"2022-04-28T17:12:49.781629Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"model = SiameseNetwork(CFG.model_name)\ncriterion = SimilarityLoss(margin=CFG.loss_margin)\ndriver = SiameseNetworkDirver(model, criterion, CFG.lr)\n\ntrainer.fit(driver, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:12:49.785001Z","iopub.execute_input":"2022-04-28T17:12:49.785842Z","iopub.status.idle":"2022-04-28T17:14:57.922232Z","shell.execute_reply.started":"2022-04-28T17:12:49.785798Z","shell.execute_reply":"2022-04-28T17:14:57.921565Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n\nfig, axes = plt.subplots(1,2, figsize = (12,4))\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nval_loss = metrics['val_loss'].dropna().reset_index(drop=True)\n\naxes[0].grid(True)\naxes[0].plot(train_loss, color=\"r\", marker=\"o\", label='train/loss')\naxes[0].plot(val_loss, color=\"b\", marker=\"x\", label='valid/loss')\naxes[0].legend(loc='upper right', fontsize=9)\n\nlr = metrics['lr'].dropna().reset_index(drop=True)\n\naxes[1].grid(True)\naxes[1].plot(lr, color=\"g\", marker=\"o\", label='learning rate')\naxes[1].legend(loc='upper right', fontsize=9)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:00.503470Z","iopub.execute_input":"2022-04-28T17:16:00.503903Z","iopub.status.idle":"2022-04-28T17:16:00.965685Z","shell.execute_reply.started":"2022-04-28T17:16:00.503862Z","shell.execute_reply":"2022-04-28T17:16:00.965029Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"data = create_dataset(CFG.test_path, CFG.test_similarity_factor, CFG.test_dissimilarity_factor)\ntest_data = pd.DataFrame(data, columns=['image1', 'image2', 'label'])\nprint(test_data.shape)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:01.779189Z","iopub.execute_input":"2022-04-28T17:16:01.779904Z","iopub.status.idle":"2022-04-28T17:16:01.801953Z","shell.execute_reply.started":"2022-04-28T17:16:01.779863Z","shell.execute_reply":"2022-04-28T17:16:01.801231Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"test_data.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:15.996198Z","iopub.execute_input":"2022-04-28T17:16:15.996454Z","iopub.status.idle":"2022-04-28T17:16:16.004404Z","shell.execute_reply.started":"2022-04-28T17:16:15.996425Z","shell.execute_reply":"2022-04-28T17:16:16.003725Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"test_dataset = SiameseDataset(test_data, transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:17.363847Z","iopub.execute_input":"2022-04-28T17:16:17.364349Z","iopub.status.idle":"2022-04-28T17:16:17.368399Z","shell.execute_reply.started":"2022-04-28T17:16:17.364311Z","shell.execute_reply":"2022-04-28T17:16:17.367702Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:18.931260Z","iopub.execute_input":"2022-04-28T17:16:18.931808Z","iopub.status.idle":"2022-04-28T17:16:20.334435Z","shell.execute_reply.started":"2022-04-28T17:16:18.931768Z","shell.execute_reply":"2022-04-28T17:16:20.333778Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"distance = []\nimg1_embeds, img2_embeds = [], []\nfor batch in predictions:\n    img1_embeds = batch[0]\n    img2_embeds = batch[1]\n    euclidean_distance = F.pairwise_distance(img1_embeds, img2_embeds, keepdim=True)\n    distance.append(euclidean_distance)\n    \npreds_dec = []\nfor batch in distance:\n    preds_dec += batch.squeeze(1).tolist()\n    \npreds = [1 if pred < 1 else 0 for pred in preds_dec]\ntrue = test_data.label.values","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:20.336166Z","iopub.execute_input":"2022-04-28T17:16:20.336422Z","iopub.status.idle":"2022-04-28T17:16:20.344386Z","shell.execute_reply.started":"2022-04-28T17:16:20.336387Z","shell.execute_reply":"2022-04-28T17:16:20.343405Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"round(accuracy_score(true, preds), 2)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:21.128646Z","iopub.execute_input":"2022-04-28T17:16:21.129291Z","iopub.status.idle":"2022-04-28T17:16:21.136697Z","shell.execute_reply.started":"2022-04-28T17:16:21.129254Z","shell.execute_reply":"2022-04-28T17:16:21.135882Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true, preds))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:16:24.746111Z","iopub.execute_input":"2022-04-28T17:16:24.746748Z","iopub.status.idle":"2022-04-28T17:16:24.758036Z","shell.execute_reply.started":"2022-04-28T17:16:24.746706Z","shell.execute_reply":"2022-04-28T17:16:24.757105Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[0])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[0])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : {}'.format(preds_dec[0]))\nprint('Actual Label : Same Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:54:30.586698Z","iopub.execute_input":"2022-04-28T17:54:30.587273Z","iopub.status.idle":"2022-04-28T17:54:30.916044Z","shell.execute_reply.started":"2022-04-28T17:54:30.587234Z","shell.execute_reply":"2022-04-28T17:54:30.915392Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[2])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[2])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : {}'.format(preds_dec[2]))\nprint('Actual Label : Different Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:54:25.613341Z","iopub.execute_input":"2022-04-28T17:54:25.613646Z","iopub.status.idle":"2022-04-28T17:54:25.958088Z","shell.execute_reply.started":"2022-04-28T17:54:25.613614Z","shell.execute_reply":"2022-04-28T17:54:25.957419Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[86])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[86])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : {}'.format(preds_dec[86]))\nprint('Actual Label : Different Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:27:25.696468Z","iopub.execute_input":"2022-04-28T18:27:25.697032Z","iopub.status.idle":"2022-04-28T18:27:26.059041Z","shell.execute_reply.started":"2022-04-28T18:27:25.696992Z","shell.execute_reply":"2022-04-28T18:27:26.058379Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[68])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[68])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : {}'.format(preds_dec[68]))\nprint('Actual Label : Same Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:55:54.109950Z","iopub.execute_input":"2022-04-28T17:55:54.110199Z","iopub.status.idle":"2022-04-28T17:55:54.448850Z","shell.execute_reply.started":"2022-04-28T17:55:54.110170Z","shell.execute_reply":"2022-04-28T17:55:54.448196Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}