{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\n!pip install transformers\n!pip install timm\n!pip install -qq albumentations==1.0.3","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:13:03.506809Z","iopub.execute_input":"2022-04-18T13:13:03.507164Z","iopub.status.idle":"2022-04-18T13:13:44.04271Z","shell.execute_reply.started":"2022-04-18T13:13:03.507076Z","shell.execute_reply":"2022-04-18T13:13:44.041779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport timm\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:31:11.107827Z","iopub.execute_input":"2022-04-18T13:31:11.108166Z","iopub.status.idle":"2022-04-18T13:31:11.116366Z","shell.execute_reply.started":"2022-04-18T13:31:11.108132Z","shell.execute_reply":"2022-04-18T13:31:11.114462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name = 'tf_efficientnet_b4' #efficient net.\n    train_path = '../input/face-images/faces/training'\n    test_path = '../input/face-images/faces/testing'\n    save_dir = './'\n    val_size = 0.2\n    seed = 42\n    batch_size = 16\n    lr = 1e-4\n    monitor = 'val_loss'\n    patience = 3\n    epochs = 20\n    accumulate = 1\n    loss_margin = 2.0\n    \n    similarity_factor = 10\n    dissimilarity_factor = 4\n    test_similarity_factor = 10\n    test_dissimilarity_factor = 3","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:13:59.267455Z","iopub.execute_input":"2022-04-18T13:13:59.26774Z","iopub.status.idle":"2022-04-18T13:13:59.27359Z","shell.execute_reply.started":"2022-04-18T13:13:59.267709Z","shell.execute_reply":"2022-04-18T13:13:59.272792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseDataset(Dataset):\n\n  def __init__(self, image_df, transform=None): #image_df contains image_id1, image_id2, label\n    self.image_df = image_df\n    self.transform = transform\n\n  def __len__(self):\n    return self.image_df.shape[0]\n\n  def __getitem__(self, index):\n    image1 = cv2.imread(self.image_df.image1.iloc[index])\n    image2 = cv2.imread(self.image_df.image2.iloc[index])\n    if self.transform is not None:\n        image1 = self.transform(image=image1)['image']\n        image2 = self.transform(image=image2)['image']\n    label = self.image_df.label.iloc[index]\n    return (image1, image2, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:00.355979Z","iopub.execute_input":"2022-04-18T13:14:00.356715Z","iopub.status.idle":"2022-04-18T13:14:00.363607Z","shell.execute_reply.started":"2022-04-18T13:14:00.356677Z","shell.execute_reply":"2022-04-18T13:14:00.362808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n\n  def __init__(self, model_name):\n    super(SiameseNetwork, self).__init__()\n    self.embed_model = timm.create_model(model_name, pretrained=True)\n    feats = self.embed_model.classifier.in_features\n    self.embed_model.classifier = nn.Linear(feats, 256)\n\n  def forward(self, image1, image2):\n    img1_embeds = self.embed_model(image1)\n    img2_embeds = self.embed_model(image2)\n    return img1_embeds, img2_embeds\n\nclass SiameseNetworkDirver(pl.LightningModule):\n\n    def __init__(self, model, criterion, lr):\n        super(SiameseNetworkDirver, self).__init__()\n        self.model = model\n        self.criterion = criterion\n\n    def forward(self, images1, images2):\n        return self.model(image1, image2)\n\n    def configure_optimizers(self):\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=CFG.lr)\n        return self.optimizer\n\n    def training_step(self, batch, batch_idx):\n        image1, image2, labels = batch[0], batch[1], batch[2]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        loss = self.criterion(img1_embeds, img2_embeds, labels)\n        logs = { 'train_loss': loss, 'lr': self.optimizer.param_groups[0]['lr'] }\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        image1, image2, labels = batch[0], batch[1], batch[2]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        loss = self.criterion(img1_embeds, img2_embeds, labels)\n        logs = { 'val_loss': loss }\n        self.log_dict(logs, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def predict_step(self, batch, batch_idx):\n        image1, image2 = batch[0], batch[1]\n        img1_embeds, img2_embeds = self.model(image1, image2)\n        return img1_embeds, img2_embeds","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:00.595674Z","iopub.execute_input":"2022-04-18T13:14:00.596257Z","iopub.status.idle":"2022-04-18T13:14:00.611923Z","shell.execute_reply.started":"2022-04-18T13:14:00.596215Z","shell.execute_reply":"2022-04-18T13:14:00.610915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )\n\ndef valid_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:00.836127Z","iopub.execute_input":"2022-04-18T13:14:00.836723Z","iopub.status.idle":"2022-04-18T13:14:00.843896Z","shell.execute_reply.started":"2022-04-18T13:14:00.836682Z","shell.execute_reply":"2022-04-18T13:14:00.843077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimilarityLoss(nn.Module):\n\n  def __init__(self, margin=2.0):\n    super(SimilarityLoss, self).__init__()\n    self.margin = margin\n\n  def forward(self, img1_embeds, img2_embeds, label):\n    euclidean_distance = F.pairwise_distance(img1_embeds, img2_embeds, keepdim=True)\n    loss = torch.mean((label*torch.pow(euclidean_distance, 2) + \n                      (1 - label)*torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:01.397593Z","iopub.execute_input":"2022-04-18T13:14:01.397986Z","iopub.status.idle":"2022-04-18T13:14:01.406797Z","shell.execute_reply.started":"2022-04-18T13:14:01.397952Z","shell.execute_reply":"2022-04-18T13:14:01.405998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def append_to_data(path, image, imgs, label, data):\n    image_path = os.path.join(path, image)\n    for img in imgs:\n        img_path = os.path.join(path, img)\n        if [img_path, image_path, label] not in data:\n            data.append([image_path, img_path, label])\n    return data\n\ndef create_dataset(path, s_factor, ds_factor):\n    data = []   \n\n    folders = os.listdir(path)\n    if 'README' in folders:\n        folders.remove('README')\n\n    file_names = {}\n    for folder in folders:\n        files = os.listdir(os.path.join(path, folder))\n        images = [os.path.join(folder, file) for file in files if file.endswith('.png')]\n        file_names[folder] = images\n\n    for folder in tqdm(folders):\n        images = file_names[folder]\n        temp = folders.copy()\n        temp.remove(folder)\n        for image in images:\n            imgs = random.sample(images, s_factor)\n            if image in imgs:\n                imgs.remove(image)\n            data = append_to_data(path, image, imgs, 1, data)\n\n            sel_fs = random.sample(temp, ds_factor)\n            imgs = []\n            for f in sel_fs:\n                imgs.append(random.sample(file_names[f], 1)[0])\n            data = append_to_data(path, image, imgs, 0, data)\n    \n    return data\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:01.627096Z","iopub.execute_input":"2022-04-18T13:14:01.627372Z","iopub.status.idle":"2022-04-18T13:14:02.41569Z","shell.execute_reply.started":"2022-04-18T13:14:01.627334Z","shell.execute_reply":"2022-04-18T13:14:02.414822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = create_dataset(CFG.train_path, CFG.similarity_factor, CFG.dissimilarity_factor)\ndataframe = pd.DataFrame(data, columns=['image1', 'image2', 'label'])\nprint(dataframe.shape)\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:03.70882Z","iopub.execute_input":"2022-04-18T13:14:03.709553Z","iopub.status.idle":"2022-04-18T13:14:03.734451Z","shell.execute_reply.started":"2022-04-18T13:14:03.709515Z","shell.execute_reply":"2022-04-18T13:14:03.733766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:04.946927Z","iopub.execute_input":"2022-04-18T13:14:04.94729Z","iopub.status.idle":"2022-04-18T13:14:04.962692Z","shell.execute_reply.started":"2022-04-18T13:14:04.94725Z","shell.execute_reply":"2022-04-18T13:14:04.961622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dataframe.label.values\ndataframe.drop('label', inplace=True, axis=1)\ntrain_data, val_data, train_labels, val_labels = train_test_split(dataframe, labels, \n                                                                  stratify=labels, \n                                                                  test_size=CFG.val_size, \n                                                                  random_state=CFG.seed)\ntrain_data['label'] = train_labels\nval_data['label'] = val_labels\n\ntransform = train_transform_object(256)\ntrain_dataset = SiameseDataset(train_data, transform)\nval_dataset = SiameseDataset(val_data, transform)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:05.267484Z","iopub.execute_input":"2022-04-18T13:14:05.267789Z","iopub.status.idle":"2022-04-18T13:14:05.283501Z","shell.execute_reply.started":"2022-04-18T13:14:05.267758Z","shell.execute_reply":"2022-04-18T13:14:05.282799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = CSVLogger(save_dir=CFG.save_dir, name=CFG.model_name+'_logs')\nlogger.log_hyperparams(CFG.__dict__)\n\ncheckpoint_callback = ModelCheckpoint(monitor=CFG.monitor,\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='{epoch:02d}-{valid_loss:.4f}-{valid_acc:.4f}',\n                                      verbose=False,\n                                      mode='min')\n\nearly_stop_callback = EarlyStopping(monitor=CFG.monitor, \n                                    patience=CFG.patience, \n                                    verbose=False, \n                                    mode=\"min\")\n\ntrainer = Trainer(\n    max_epochs=CFG.epochs,\n    gpus=[0],\n    accumulate_grad_batches=CFG.accumulate,\n    callbacks=[checkpoint_callback, early_stop_callback], \n    logger=logger,\n    weights_summary='top',\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:06.465815Z","iopub.execute_input":"2022-04-18T13:14:06.466305Z","iopub.status.idle":"2022-04-18T13:14:06.541879Z","shell.execute_reply.started":"2022-04-18T13:14:06.466268Z","shell.execute_reply":"2022-04-18T13:14:06.541166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SiameseNetwork(CFG.model_name)\ncriterion = SimilarityLoss(margin=CFG.loss_margin)\ndriver = SiameseNetworkDirver(model, criterion, CFG.lr)\n\ntrainer.fit(driver, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:14:08.396342Z","iopub.execute_input":"2022-04-18T13:14:08.396926Z","iopub.status.idle":"2022-04-18T13:21:55.079061Z","shell.execute_reply.started":"2022-04-18T13:14:08.396883Z","shell.execute_reply":"2022-04-18T13:21:55.078251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n\nfig, axes = plt.subplots(1,2, figsize = (12,4))\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nval_loss = metrics['val_loss'].dropna().reset_index(drop=True)\n\naxes[0].grid(True)\naxes[0].plot(train_loss, color=\"r\", marker=\"o\", label='train/loss')\naxes[0].plot(val_loss, color=\"b\", marker=\"x\", label='valid/loss')\naxes[0].legend(loc='upper right', fontsize=9)\n\nlr = metrics['lr'].dropna().reset_index(drop=True)\n\naxes[1].grid(True)\naxes[1].plot(lr, color=\"g\", marker=\"o\", label='learning rate')\naxes[1].legend(loc='upper right', fontsize=9)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:23:19.80827Z","iopub.execute_input":"2022-04-18T13:23:19.80855Z","iopub.status.idle":"2022-04-18T13:23:20.179804Z","shell.execute_reply.started":"2022-04-18T13:23:19.808521Z","shell.execute_reply":"2022-04-18T13:23:20.179111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = create_dataset(CFG.test_path, CFG.test_similarity_factor, CFG.test_dissimilarity_factor)\ntest_data = pd.DataFrame(data, columns=['image1', 'image2', 'label'])\nprint(test_data.shape)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:23:29.895515Z","iopub.execute_input":"2022-04-18T13:23:29.896053Z","iopub.status.idle":"2022-04-18T13:23:29.907687Z","shell.execute_reply.started":"2022-04-18T13:23:29.896015Z","shell.execute_reply":"2022-04-18T13:23:29.906782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:23:31.105613Z","iopub.execute_input":"2022-04-18T13:23:31.106322Z","iopub.status.idle":"2022-04-18T13:23:31.113348Z","shell.execute_reply.started":"2022-04-18T13:23:31.106283Z","shell.execute_reply":"2022-04-18T13:23:31.112566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = SiameseDataset(test_data, transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:23:32.556847Z","iopub.execute_input":"2022-04-18T13:23:32.557483Z","iopub.status.idle":"2022-04-18T13:23:32.562257Z","shell.execute_reply.started":"2022-04-18T13:23:32.557442Z","shell.execute_reply":"2022-04-18T13:23:32.561272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:23:34.025497Z","iopub.execute_input":"2022-04-18T13:23:34.026355Z","iopub.status.idle":"2022-04-18T13:23:38.699012Z","shell.execute_reply.started":"2022-04-18T13:23:34.0263Z","shell.execute_reply":"2022-04-18T13:23:38.698251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distance = []\nimg1_embeds, img2_embeds = [], []\nfor batch in predictions:\n    img1_embeds = batch[0]\n    img2_embeds = batch[1]\n    euclidean_distance = F.pairwise_distance(img1_embeds, img2_embeds, keepdim=True)\n    distance.append(euclidean_distance)\n    \npreds_dec = []\nfor batch in distance:\n    preds_dec += batch.squeeze(1).tolist()\n    \npreds = [1 if pred < 1 else 0 for pred in preds_dec]\ntrue = test_data.label.values","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:25:27.596989Z","iopub.execute_input":"2022-04-18T13:25:27.597438Z","iopub.status.idle":"2022-04-18T13:25:27.604093Z","shell.execute_reply.started":"2022-04-18T13:25:27.5974Z","shell.execute_reply":"2022-04-18T13:25:27.603173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(accuracy_score(true, preds), 2)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:46:29.787677Z","iopub.execute_input":"2022-04-18T13:46:29.787953Z","iopub.status.idle":"2022-04-18T13:46:29.794759Z","shell.execute_reply.started":"2022-04-18T13:46:29.787922Z","shell.execute_reply":"2022-04-18T13:46:29.793893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true, preds))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:25:33.576301Z","iopub.execute_input":"2022-04-18T13:25:33.576845Z","iopub.status.idle":"2022-04-18T13:25:33.588537Z","shell.execute_reply.started":"2022-04-18T13:25:33.576807Z","shell.execute_reply":"2022-04-18T13:25:33.587413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[0])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[0])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : 0.98')\nprint('Actual Label : Same Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:44:32.50866Z","iopub.execute_input":"2022-04-18T13:44:32.508954Z","iopub.status.idle":"2022-04-18T13:44:32.8574Z","shell.execute_reply.started":"2022-04-18T13:44:32.508922Z","shell.execute_reply":"2022-04-18T13:44:32.856747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(8, 5))\n\nimage1 = Image.open(test_data.image1.iloc[9])\naxes[0].imshow(image1)\n\nimage2 = Image.open(test_data.image2.iloc[9])\naxes[1].imshow(image2)\n\nprint('Predicted Euclidean Distance : 1.12')\nprint('Actual Label : Different Person')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:44:06.587643Z","iopub.execute_input":"2022-04-18T13:44:06.588275Z","iopub.status.idle":"2022-04-18T13:44:06.973568Z","shell.execute_reply.started":"2022-04-18T13:44:06.588234Z","shell.execute_reply":"2022-04-18T13:44:06.972913Z"},"trusted":true},"execution_count":null,"outputs":[]}]}